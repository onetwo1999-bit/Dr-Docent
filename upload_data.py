import os
import sys
import time
import math
from pathlib import Path

import pandas as pd
from supabase import create_client
from dotenv import load_dotenv

# ìŠ¤í¬ë¦½íŠ¸ ìœ„ì¹˜ = í”„ë¡œì íŠ¸ ë£¨íŠ¸ (CSV/ì±…ê°ˆí”¼ëŠ” ì—¬ê¸° ê¸°ì¤€)
SCRIPT_DIR = Path(__file__).resolve().parent

# .env.localì—ì„œ ì„¤ì • ë¶ˆëŸ¬ì˜¤ê¸°
load_dotenv(SCRIPT_DIR / ".env.local")
url = os.getenv("NEXT_PUBLIC_SUPABASE_URL")
key = os.getenv("NEXT_PUBLIC_SUPABASE_ANON_KEY")
supabase = create_client(url, key)

# ì¸ìë¡œ CSV ì§€ì • ì‹œ part2 ì—…ë¡œë“œ, ì—†ìœ¼ë©´ ê¸°ë³¸ 25ë§Œ ê±´ìš©
if len(sys.argv) >= 2:
    CSV_FILE = sys.argv[1]
    base = os.path.splitext(os.path.basename(CSV_FILE))[0]
    STATUS_FILE = f"upload_status_{base}.txt"
    TOTAL_EXPECTED = 0
else:
    CSV_FILE = "processed_food_db_final_250k.csv"
    STATUS_FILE = "upload_status.txt"
    TOTAL_EXPECTED = 250_000

# ê²½ë¡œëŠ” í•­ìƒ ìŠ¤í¬ë¦½íŠ¸ í´ë” ê¸°ì¤€ ì ˆëŒ€ ê²½ë¡œë¡œ ì‚¬ìš©
CSV_PATH = SCRIPT_DIR / CSV_FILE
STATUS_PATH = SCRIPT_DIR / STATUS_FILE

BATCH_SIZE = 500


def _sanitize_record(rec: dict) -> dict:
    """
    Supabase JSON ì§ë ¬í™” ì—ëŸ¬ ë°©ì§€ë¥¼ ìœ„í•´ NaN/Inf ë“± out-of-range float ê°’ì„ Noneìœ¼ë¡œ ì¹˜í™˜.
    """
    cleaned = {}
    for k, v in rec.items():
        if isinstance(v, float):
            # NaN, Inf, -Inf ëª¨ë‘ JSONì— í—ˆìš©ë˜ì§€ ì•Šìœ¼ë¯€ë¡œ Noneìœ¼ë¡œ ì¹˜í™˜
            if not math.isfinite(v):
                cleaned[k] = None
            else:
                cleaned[k] = v
        else:
            cleaned[k] = v
    return cleaned

def run_upload():
    if not CSV_PATH.exists():
        print(f"âŒ CSV íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {CSV_PATH}")
        return

    # 1. ì–´ë””ê¹Œì§€ ì˜¬ë ¸ëŠ”ì§€ í™•ì¸ (ì±…ê°ˆí”¼ëŠ” ìŠ¤í¬ë¦½íŠ¸ í´ë” ê¸°ì¤€)
    start_row = 0
    if STATUS_PATH.exists():
        with open(STATUS_PATH, "r") as f:
            start_row = int(f.read().strip())

    # 2. ë°ì´í„° ì½ê¸°
    df = pd.read_csv(CSV_PATH)
    total_rows = len(df)

    print(f"ğŸš€ {CSV_FILE} â€” ì´ {total_rows}ê±´ ì¤‘ {start_row}ë²ˆë¶€í„° ì—…ë¡œë“œ ì¬ê°œ!")

    # 3. ë£¨í”„ ëŒë©° ì—…ë¡œë“œ
    for i in range(start_row, total_rows, BATCH_SIZE):
        raw_batch = df.iloc[i : i + BATCH_SIZE].to_dict(orient="records")
        # NaN/Inf ë“± JSON ë¹„í˜¸í™˜ ê°’ ì •ë¦¬
        batch = [_sanitize_record(r) for r in raw_batch]
        
        try:
            # ìˆ˜íŒŒë² ì´ìŠ¤ë¡œ ë°œì†¡
            supabase.table("food_knowledge").insert(batch).execute()
            
            # ì„±ê³µí•˜ë©´ í˜„ì¬ ìœ„ì¹˜ë¥¼ ë©”ëª¨ì¥ì— ê¸°ë¡ (ì±…ê°ˆí”¼ ë¼ìš°ê¸°)
            current_pos = i + len(batch)
            with open(STATUS_PATH, "w") as f:
                f.write(str(current_pos))

            # ì§„í–‰ ë¡œê·¸: [ì„±ê³µ] XXX / 250,000 ì™„ë£Œ (ì§„í–‰ë¥ : XX%)
            progress_base = TOTAL_EXPECTED if TOTAL_EXPECTED > 0 else total_rows
            pct = (current_pos / progress_base) * 100 if progress_base else 0
            print(f"[ì„±ê³µ] {current_pos} / {progress_base:,} ì™„ë£Œ (ì§„í–‰ë¥ : {pct:.1f}%)")

            # ì„œë²„ ë¶€ë‹´ ì™„í™”ë¥¼ ìœ„í•œ ì§§ì€ íœ´ì‹
            time.sleep(0.5)
            
        except Exception as e:
            print(f"ğŸš¨ {i}ë²ˆ ì§€ì ì—ì„œ ë©ˆì¶¤: {e}")
            print("âŒ ì¸í„°ë„· ì—°ê²° ë“±ì„ í™•ì¸í•˜ê³  ë‹¤ì‹œ ì‹¤í–‰í•˜ì„¸ìš”. ë©ˆì¶˜ ê³³ë¶€í„° ì´ì–´ì§‘ë‹ˆë‹¤.")
            break

if __name__ == "__main__":
    run_upload()
