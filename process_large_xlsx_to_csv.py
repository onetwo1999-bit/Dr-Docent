"""
ì—‘ì…€ â†’ Supabase ì—…ë¡œë“œìš© CSV ë³€í™˜ (ë©”ëª¨ë¦¬ ì ˆì•½ ì²­í¬ ì²˜ë¦¬)

- openpyxl read_only=Trueë¡œ ì—‘ì…€ ìŠ¤íŠ¸ë¦¬ë°, 1ë§Œ í–‰ ë‹¨ìœ„ ì²­í‚¹ í›„ CSVì— ì´ì–´ë¶™ì´ê¸°
- 9ê°œ ì˜ë¬¸ ì»¬ëŸ¼, 1ì¸ë¶„ ì˜ì–‘ í™˜ì‚°, clinical_insight, synthetic_qa ìƒì„± (ë™ì¼ ë¡œì§)

ì‹¤í–‰ ì˜ˆ:
  python process_large_xlsx_to_csv.py
    â†’ raw_food_db.xlsx â†’ processed_food_db_final_250k.csv (ê¸°ë³¸ 25ë§Œ ê±´ìš©)

  python process_large_xlsx_to_csv.py raw_food_db_part2.xlsx processed_food_db_part2.csv
    â†’ part2 ì „ìš© (ê¸°ì¡´ _final_250k.csv íŒŒì¼ì€ ê±´ë“œë¦¬ì§€ ì•ŠìŒ)
"""

import json
import sys
from pathlib import Path

import pandas as pd

try:
    from openpyxl import load_workbook
except ImportError:
    raise SystemExit("âŒ openpyxl í•„ìš”: pip install openpyxl")

# ì…ì¶œë ¥: ì¸ì 2ê°œ ì£¼ë©´ part2 ë“± ë³„ë„ íŒŒì¼ë¡œ ë™ì‘, ì—†ìœ¼ë©´ ê¸°ë³¸ 25ë§Œ ê±´ìš©
if len(sys.argv) >= 3:
    INPUT_XLSX = sys.argv[1]
    OUTPUT_CSV = sys.argv[2]
else:
    INPUT_XLSX = "raw_food_db.xlsx"
    OUTPUT_CSV = "processed_food_db_final_250k.csv"

CHUNK_SIZE = 10_000

NUTRIENT_COLS = ["calories", "protein", "fat", "carbs", "sugar", "sodium"]
FINAL_COLS = [
    "food_name", "calories", "protein", "fat", "carbs", "sugar", "sodium",
    "clinical_insight", "synthetic_qa",
]

# ì›ë³¸ í•œê¸€ ì»¬ëŸ¼ â†’ ìˆ˜íŒŒë² ì´ìŠ¤ ì˜ë¬¸ ì»¬ëŸ¼ (ì—¬ëŸ¬ í‘œê¸° í—ˆìš©)
COLUMN_MAPPING = [
    ("ì‹í’ˆëª…", "food_name"),
    ("ì—ë„ˆì§€(kcal)", "calories"),
    ("ì—ë„ˆì§€", "calories"),
    ("ë‹¨ë°±ì§ˆ(g)", "protein"),
    ("ë‹¨ë°±ì§ˆ", "protein"),
    ("ì§€ë°©(g)", "fat"),
    ("ì§€ë°©", "fat"),
    ("íƒ„ìˆ˜í™”ë¬¼(g)", "carbs"),
    ("íƒ„ìˆ˜í™”ë¬¼", "carbs"),
    ("ë‹¹ë¥˜(g)", "sugar"),
    ("ë‹¹ë¥˜", "sugar"),
    ("ë‚˜íŠ¸ë¥¨(mg)", "sodium"),
    ("ë‚˜íŠ¸ë¥¨", "sodium"),
]

WEIGHT_KEYWORDS = ["1íšŒì œê³µëŸ‰", "1íšŒ ì œê³µëŸ‰", "ì´ë‚´ìš©ëŸ‰", "ì¤‘ëŸ‰", "ë‚´ìš©ëŸ‰", "1íšŒë¶„ëŸ‰"]


def find_weight_column(columns):
    for kw in WEIGHT_KEYWORDS:
        for c in columns:
            if kw in str(c):
                return c
    return None


def apply_column_mapping(df: pd.DataFrame) -> pd.DataFrame:
    renames = {}
    seen_eng = set()
    for kor, eng in COLUMN_MAPPING:
        if kor in df.columns and eng not in seen_eng:
            renames[kor] = eng
            seen_eng.add(eng)
    return df.rename(columns=renames)


def apply_serving_conversion(df: pd.DataFrame, weight_col) -> pd.DataFrame:
    df = df.copy()
    if weight_col is None or weight_col not in df.columns:
        for col in NUTRIENT_COLS:
            if col in df.columns:
                df[col] = pd.to_numeric(df[col], errors="coerce").fillna(0)
        return df
    weight_series = pd.to_numeric(df[weight_col], errors="coerce").fillna(100)
    ratio = weight_series / 100.0
    for col in NUTRIENT_COLS:
        if col in df.columns:
            df[col] = pd.to_numeric(df[col], errors="coerce").fillna(0)
            df[col] = (df[col] * ratio).round(1)
    return df


def add_clinical_insight(row: pd.Series) -> str:
    sodium = row.get("sodium") or 0
    sugar = row.get("sugar") or 0
    protein = row.get("protein") or 0
    parts = []
    if sodium >= 500:
        parts.append(f"1ì¸ë¶„ ê¸°ì¤€ ë‚˜íŠ¸ë¥¨ {int(sodium)}mgë¡œ ê³ í˜ˆì•• ì£¼ì˜ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
    if sugar >= 10:
        parts.append(f"ë‹¹ë¥˜ {sugar}g í¬í•¨ìœ¼ë¡œ ë‹¹ë‡¨ ê´€ë¦¬ ì‹œ ì–‘ì„ ì¡°ì ˆí•˜ì„¸ìš”.")
    if protein >= 15:
        parts.append("ë‹¨ë°±ì§ˆì´ í’ë¶€í•´ ê·¼ì„±ì¥Â·ìœ ì§€ì— ë„ì›€ì´ ë©ë‹ˆë‹¤.")
    if not parts:
        return "ê· í˜• ì¡íŒ ì˜ì–‘ ì„±ë¶„ì…ë‹ˆë‹¤."
    return " ".join(parts)


def add_synthetic_qa(row: pd.Series) -> str:
    name = row.get("food_name") or ""
    cal = row.get("calories") or 0
    insight = row.get("clinical_insight") or ""
    return json.dumps({
        "question": f"{name}ì˜ ì¹¼ë¡œë¦¬ì™€ ì˜ì–‘ì€?",
        "answer": f"1ì¸ë¶„ ê¸°ì¤€ {cal}kcalì´ë©°, {insight}"
    }, ensure_ascii=False)


def stream_xlsx_rows(path: Path, chunk_size: int):
    """ì—‘ì…€ì„ read_onlyë¡œ ì—´ê³  í–‰ì„ ì²­í¬ ë‹¨ìœ„ë¡œ yield (ë©”ëª¨ë¦¬ ì ˆì•½)."""
    wb = load_workbook(path, read_only=True, data_only=True)
    ws = wb.active
    header = None
    chunk = []
    for row in ws.iter_rows(values_only=True):
        if header is None:
            header = [str(c) if c is not None else "" for c in row]
            continue
        chunk.append(list(row))
        if len(chunk) >= chunk_size:
            yield header, chunk
            chunk = []
    if chunk:
        yield header, chunk
    wb.close()


def main():
    folder = Path(__file__).resolve().parent
    xlsx_path = folder / INPUT_XLSX
    csv_path = folder / OUTPUT_CSV

    if not xlsx_path.exists():
        print(f"âŒ í˜„ì¬ í´ë”ì— {INPUT_XLSX} ì´(ê°€) ì—†ìŠµë‹ˆë‹¤.")
        return

    print(f"ğŸ“¥ {INPUT_XLSX} â†’ {OUTPUT_CSV} (ì²­í¬ë‹¹ {CHUNK_SIZE:,}í–‰)")
    weight_col_global = None
    total_rows = 0
    first_chunk = True

    for header, rows in stream_xlsx_rows(xlsx_path, CHUNK_SIZE):
        n_cols = len(header)
        # ì…€ ê°œìˆ˜ê°€ í—¤ë”ì™€ ë‹¤ë¥¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ê¸¸ì´ ë§ì¶¤
        normalized = [(r + [None] * n_cols)[:n_cols] for r in rows]
        df = pd.DataFrame(normalized, columns=header)
        # ì²« ì²­í¬ì—ì„œë§Œ ê¸°ì¤€ ì¤‘ëŸ‰ ì»¬ëŸ¼ ê²°ì •
        if weight_col_global is None:
            weight_col_global = find_weight_column(df.columns)
            if weight_col_global:
                print(f"âš–ï¸ ê¸°ì¤€ ì¤‘ëŸ‰ ì»¬ëŸ¼: '{weight_col_global}' (1ì¸ë¶„ í™˜ì‚°)")
            else:
                print("âš–ï¸ ê¸°ì¤€ ì¤‘ëŸ‰ ì»¬ëŸ¼ ì—†ìŒ â†’ 100g ê¸°ì¤€ ìœ ì§€")

        df = apply_column_mapping(df)
        missing = [c for c in ["food_name"] + NUTRIENT_COLS if c not in df.columns]
        if missing:
            print(f"âŒ ì›ë³¸ì— í•„ìˆ˜ ì»¬ëŸ¼ ì—†ìŒ: {missing}. ì›ë³¸ ì»¬ëŸ¼: {list(df.columns)[:20]}...")
            return

        df = apply_serving_conversion(df, weight_col_global)
        df["clinical_insight"] = df.apply(add_clinical_insight, axis=1)
        df["synthetic_qa"] = df.apply(add_synthetic_qa, axis=1)
        out = df[FINAL_COLS]

        out.to_csv(
            csv_path,
            index=False,
            encoding="utf-8-sig",
            mode="w" if first_chunk else "a",
            header=first_chunk,
        )
        total_rows += len(out)
        first_chunk = False

        # 1ë§Œ ê±´ë§ˆë‹¤ "Xë§Œ ê±´ ë³€í™˜ ì™„ë£Œ" ë¡œê·¸ ì¶œë ¥
        if total_rows and total_rows % 10_000 == 0:
            print(f"   âœ… {total_rows // 10_000}ë§Œ ê±´ ë³€í™˜ ì™„ë£Œ")

    print(f"âœ… {OUTPUT_CSV} ì €ì¥ ì™„ë£Œ (ì´ {total_rows:,}í–‰, 9ê°œ ì»¬ëŸ¼)")


if __name__ == "__main__":
    main()
